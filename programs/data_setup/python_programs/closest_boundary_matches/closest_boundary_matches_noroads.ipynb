{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af0ba61c-3157-420e-94dc-77ab2def8afc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-01T18:24:43.032334Z",
     "iopub.status.busy": "2022-11-01T18:24:43.032166Z",
     "iopub.status.idle": "2022-11-01T18:24:43.036690Z",
     "shell.execute_reply": "2022-11-01T18:24:43.036070Z",
     "shell.execute_reply.started": "2022-11-01T18:24:43.032279Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# File name:    \"closest_boundary_no_roads.ipynb\"\n",
    "#\n",
    "# Project title:    Boston Affordable Housing project (visting scholar porject)\n",
    "#\n",
    "# Description:    This program is similar to the original closest_boundary file\n",
    "#                 except it matches based on admissable boundaries that do not\n",
    "#                 overlap with minor roads. The original matching program had \n",
    "#                 already removed highways and major roads. This is primarily \n",
    "#                 as as robustness check. In order to properly assign properties \n",
    "#                 we need to re-run the matching alogrithm.\n",
    "#\n",
    "# Inputs:    ./warren_address_points_assigned.shp\n",
    "#            ./adm3_no_roads_crs26986.shp\n",
    "#            ./regulation_types_moreregs.dta\n",
    "#\n",
    "# Outputs:    ./closest_boundary_no_roads_<date>.csv\n",
    "#             ./closest_boundary_no_roads_log.txt\n",
    "#\n",
    "# Created:    10/12/2022\n",
    "# Updated:    10/17/2022\n",
    "#\n",
    "# Author:    Nicholas Chiumenti\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34a2a2ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-01T18:24:43.037591Z",
     "iopub.status.busy": "2022-11-01T18:24:43.037375Z",
     "iopub.status.idle": "2022-11-01T18:24:43.764349Z",
     "shell.execute_reply": "2022-11-01T18:24:43.762920Z",
     "shell.execute_reply.started": "2022-11-01T18:24:43.037575Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "from shapely.geometry import Point, LineString\n",
    "from shapely.ops import nearest_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e12db5de-45c9-41d8-9f98-3105ca5cc8c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-01T18:24:43.767821Z",
     "iopub.status.busy": "2022-11-01T18:24:43.767481Z",
     "iopub.status.idle": "2022-11-01T18:24:43.773288Z",
     "shell.execute_reply": "2022-11-01T18:24:43.772463Z",
     "shell.execute_reply.started": "2022-11-01T18:24:43.767791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running closest_boundary_no_roads program...\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "print(\"Running closest_boundary_no_roads program...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f388a950-fc60-4862-a5bc-51ccf2aff2fd",
   "metadata": {},
   "source": [
    "# Set all data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73f0bcdd-1e64-460c-b58e-dac45636fb2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-01T18:24:43.774722Z",
     "iopub.status.busy": "2022-11-01T18:24:43.774196Z",
     "iopub.status.idle": "2022-11-01T18:24:43.787790Z",
     "shell.execute_reply": "2022-11-01T18:24:43.787092Z",
     "shell.execute_reply.started": "2022-11-01T18:24:43.774699Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prop_path = \"/home/a1nfc04/python_projects/closest_boundary_py/points_shapefiles/warren_address_points_assigned.shp\"\n",
    "\n",
    "boundary_path = \"/home/a1nfc04/Documents/boston_zoning_sdrive/data/shapefiles/zoning_boundaries/adm3_no_roads_crs26986/adm3_no_roads_crs26986.shp\"\n",
    "\n",
    "reg_path = \"/home/a1nfc04/Documents/boston_zoning_sdrive/data/regulation_data/regulation_types_moreregs.dta\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01076b6a-73ef-44fe-a2be-f7de7eb762cc",
   "metadata": {},
   "source": [
    "# Import data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "943f2358-d6bc-46d7-9c9b-2117454e3c29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-01T18:24:43.789111Z",
     "iopub.status.busy": "2022-11-01T18:24:43.788663Z",
     "iopub.status.idle": "2022-11-01T18:24:43.850060Z",
     "shell.execute_reply": "2022-11-01T18:24:43.849222Z",
     "shell.execute_reply.started": "2022-11-01T18:24:43.789091Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading regulation file!\n"
     ]
    }
   ],
   "source": [
    "# load in regulatory data\n",
    "regs_df = pd.read_stata(reg_path)\n",
    "\n",
    "# error check reg data\n",
    "assert len(regs_df) == 7011, \"incorrect number of observations for regulatory data\"\n",
    "\n",
    "print(\"Finished loading regulation file!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1807484-7815-40f7-83ae-fd4a1e93768e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-01T18:24:43.851472Z",
     "iopub.status.busy": "2022-11-01T18:24:43.851010Z",
     "iopub.status.idle": "2022-11-01T18:25:27.663169Z",
     "shell.execute_reply": "2022-11-01T18:25:27.662330Z",
     "shell.execute_reply.started": "2022-11-01T18:24:43.851450Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading property file!\n"
     ]
    }
   ],
   "source": [
    "# load property shape file as geodataframe\n",
    "prop_gdf = gpd.read_file(prop_path)\n",
    "\n",
    "# convert crs to epsg=26986\n",
    "prop_gdf.to_crs(\"EPSG:26986\", inplace=True)\n",
    "\n",
    "# error checks\n",
    "assert len(prop_gdf) == 632286, \"incorrect observation count for prop_gdf\"\n",
    "assert prop_gdf.crs == 26986, \"incorrect crs for prop_gdf\"\n",
    "\n",
    "print(\"Finished loading property file!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a900bd66-4476-4b49-9d49-9be8e9e8d86b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-01T18:25:27.664495Z",
     "iopub.status.busy": "2022-11-01T18:25:27.664267Z",
     "iopub.status.idle": "2022-11-01T18:25:29.763250Z",
     "shell.execute_reply": "2022-11-01T18:25:29.762480Z",
     "shell.execute_reply.started": "2022-11-01T18:25:27.664476Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading boundary file!\n"
     ]
    }
   ],
   "source": [
    "# load no minor roads boundary shape file as geodataframe\n",
    "boundary_gdf = gpd.read_file(boundary_path)\n",
    "\n",
    "boundary_gdf\n",
    "\n",
    "# clean up town names\n",
    "boundary_gdf['municipal'] = boundary_gdf['municipal'].str.upper()    \n",
    "boundary_gdf['municipal'].replace({'MARLBOROUGH':'MARLBORO'}, inplace=True)\n",
    "boundary_gdf['municipal'].replace({'FOXBOROUGH':'FOXBORO'}, inplace=True)\n",
    "boundary_gdf['municipal'].replace({'SOUTHBOROUGH':'SOUTHBORO'}, inplace=True)\n",
    "boundary_gdf['municipal'].replace({'BOXBOROUGH':'BOXBORO'}, inplace=True)\n",
    "\n",
    "# ensure open enrollment municipalities points match regardless of school attendance zone \n",
    "boundary_gdf.loc[(boundary_gdf.municipal == 'ACTON'),'ncessch']='ACTON'\n",
    "boundary_gdf.loc[(boundary_gdf.municipal == 'BOLTON'),'ncessch']='BOLTON'\n",
    "boundary_gdf.loc[(boundary_gdf.municipal == 'BOSTON'),'ncessch']='BOSTON'\n",
    "boundary_gdf.loc[(boundary_gdf.municipal == 'BOXBORO'),'ncessch']='BOXBORO'\n",
    "boundary_gdf.loc[(boundary_gdf.municipal == 'ESSEX'),'ncessch']='ESSEX'\n",
    "boundary_gdf.loc[(boundary_gdf.municipal == 'MANCHESTER'),'ncessch']='MANCHESTER'\n",
    "boundary_gdf.loc[(boundary_gdf.municipal == 'SAUGUS'),'ncessch']='SAUGUS'\n",
    "boundary_gdf.loc[(boundary_gdf.municipal == 'STOW'),'ncessch']='STOW'\n",
    "\n",
    "# rename original boundary id name\n",
    "boundary_gdf.rename(columns={\"UNIQUE_ID\":\"boundary_id_orig\"}, inplace=True)\n",
    "\n",
    "# create a static unique id\n",
    "boundary_gdf[\"unique_id\"] = boundary_gdf.index\n",
    "\n",
    "# trim fields from boundary dataframe to make it easier to handle\n",
    "boundary_gdf = boundary_gdf[[\"unique_id\", \"boundary_id_orig\",\n",
    "                             \"municipal\", \"ncessch\", \"zo_usety\",\n",
    "                             \"LEFT_FID\", \"RIGHT_FID\", \"geometry\"]]\n",
    "\n",
    "# error checks\n",
    "assert len(boundary_gdf) == 32606, \"incorrect observation count for boundary_gdf\"\n",
    "assert boundary_gdf.crs == 26986, \"incorrect crs for boundary_gdf\"\n",
    "\n",
    "print(\"Finished loading boundary file!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0d7c37a-0a78-49c8-ac68-ce1f8410c037",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-01T18:25:29.764500Z",
     "iopub.status.busy": "2022-11-01T18:25:29.764268Z",
     "iopub.status.idle": "2022-11-01T18:25:29.868483Z",
     "shell.execute_reply": "2022-11-01T18:25:29.867750Z",
     "shell.execute_reply.started": "2022-11-01T18:25:29.764480Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished checking town coverage for errors!\n"
     ]
    }
   ],
   "source": [
    "# check municipalities in points that are not in lines\n",
    "muni_points = prop_gdf['W_CITY'].unique()\n",
    "\n",
    "muni_lines = boundary_gdf['municipal'].unique()\n",
    "\n",
    "missing_munis = list(set(muni_points) - set(muni_lines))\n",
    "\n",
    "assert all(elem in [\"SAUGUS\", \"STOW\"]  for elem in missing_munis), \"missing munis is not correct\"\n",
    "\n",
    "# confirm the CRSs are the same\n",
    "assert prop_gdf.crs == boundary_gdf.crs, \"crs between points and boundaries do not match\"\n",
    "\n",
    "print(\"Finished checking town coverage for errors!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7166c8-7c30-4656-8a2d-a140f07fc6e3",
   "metadata": {},
   "source": [
    "# Match properties to closest boundaries left/right side, keep closest 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c6f034b-adcc-4973-9f2c-46ca9ddca561",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-01T18:25:29.903376Z",
     "iopub.status.busy": "2022-11-01T18:25:29.903149Z",
     "iopub.status.idle": "2022-11-01T18:26:30.175397Z",
     "shell.execute_reply": "2022-11-01T18:26:30.174635Z",
     "shell.execute_reply.started": "2022-11-01T18:25:29.903355Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished matching properties to left/right side boundaries!\n"
     ]
    }
   ],
   "source": [
    "# match properties to all possible left side boundaries\n",
    "left_side_matches = prop_gdf.merge(boundary_gdf, \n",
    "                               how=\"inner\",\n",
    "                               left_on=[\"W_CITY\", \"ncessch\", \"zo_usety\", \"l_r_fid\"],\n",
    "                               right_on=[\"municipal\", \"ncessch\", \"zo_usety\", \"LEFT_FID\"],\n",
    "                               suffixes=(\"_x\", \"_fid\")\n",
    "                              )\n",
    "\n",
    "# tag as a left side match\n",
    "left_side_matches.loc[:, \"boundary_side\"] = \"LEFT\"\n",
    "\n",
    "# match properties to all possible right side boundaries\n",
    "right_side_matches = prop_gdf.merge(boundary_gdf, \n",
    "                               how=\"inner\",\n",
    "                               left_on=[\"W_CITY\", \"ncessch\", \"zo_usety\", \"l_r_fid\"],\n",
    "                               right_on=[\"municipal\", \"ncessch\", \"zo_usety\", \"RIGHT_FID\"],\n",
    "                               suffixes=(\"_x\", \"_fid\")\n",
    "                              )\n",
    "\n",
    "# tag as a right side match\n",
    "right_side_matches.loc[:, \"boundary_side\"] = \"RIGHT\"\n",
    "\n",
    "# append the two matched dfs together into one\n",
    "matches_df = pd.concat([left_side_matches, right_side_matches], ignore_index=True)\n",
    "\n",
    "# calculate the distance from point to matching boundary\n",
    "# note this distance is meaningless b/c we are using lat/lon coords\n",
    "matches_df.loc[:,\"dist_m\"] = gpd.GeoSeries(matches_df[\"geometry_x\"]).distance(gpd.GeoSeries(matches_df[\"geometry_fid\"]))\n",
    "\n",
    "# sort by prop_id and distance \n",
    "matches_df.sort_values(by=[\"PROP_ID\", \"dist_m\"], ascending=True, inplace=True)\n",
    "\n",
    "# keep the 5 closest matches\n",
    "matches_df = matches_df.groupby(\"PROP_ID\").head(5).reset_index(drop=True)\n",
    "\n",
    "matches_df.loc[:, \"match_num\"] = matches_df.groupby(\"PROP_ID\")[\"dist_m\"].rank(method=\"first\", ascending=True)\n",
    "\n",
    "# error checks\n",
    "assert len(matches_df) == 2429563, \"incorrect observation count for matches_df\"\n",
    "\n",
    "side_counts = dict(matches_df[\"boundary_side\"].value_counts())\n",
    "assert side_counts[\"LEFT\"] == 1230910, \"incorrect count of left side matches\"\n",
    "assert side_counts[\"RIGHT\"] == 1198653, \"incorrect count of right side matches\"\n",
    "\n",
    "print(\"Finished matching properties to left/right side boundaries!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26726d6-d617-4068-8efa-546a32ef1fc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-13T19:33:08.002973Z",
     "iopub.status.busy": "2022-10-13T19:33:08.002714Z",
     "iopub.status.idle": "2022-10-13T19:33:08.506341Z",
     "shell.execute_reply": "2022-10-13T19:33:08.505878Z",
     "shell.execute_reply.started": "2022-10-13T19:33:08.002955Z"
    },
    "tags": []
   },
   "source": [
    "# Add on the regulatory data and create <home_> and <nn_> variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3534274-54fa-4d9d-9768-104c93149768",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-01T18:26:30.176831Z",
     "iopub.status.busy": "2022-11-01T18:26:30.176553Z",
     "iopub.status.idle": "2022-11-01T18:26:36.936560Z",
     "shell.execute_reply": "2022-11-01T18:26:36.935868Z",
     "shell.execute_reply.started": "2022-11-01T18:26:30.176809Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished adding regulation variables!\n"
     ]
    }
   ],
   "source": [
    "# define list of reg_df variables and reglation variables\n",
    "reg_cols = [\"zo_usety_y\", \"mxht_eff\", \"dupac_eff\", \"mulfam\", \"reg_type_y\", \"LRID\", \"minlotsize\", \"maxdu\"]\n",
    "reg_list = [\"mxht_eff\", \"dupac_eff\", \"mulfam\", \"minlotsize\", \"maxdu\"]\n",
    "\n",
    "# merge regulation data using left side fid\n",
    "matches_df = matches_df.merge(regs_df, how=\"left\", left_on=\"LEFT_FID\", right_on=\"LRID\", suffixes=(\"\", \"_y\"))\n",
    "\n",
    "# assign left side regulations to home_, right side to nn_\n",
    "for reg in reg_list:\n",
    "    matches_df.loc[matches_df[\"boundary_side\"]==\"LEFT\", f\"home_{reg}\"] = matches_df[f\"{reg}\"]\n",
    "    matches_df.loc[matches_df[\"boundary_side\"]==\"RIGHT\", f\"nn_{reg}\"] = matches_df[f\"{reg}\"]\n",
    "\n",
    "# drop merged reg_df variables\n",
    "matches_df.drop(columns=reg_cols, inplace=True)\n",
    "\n",
    "# emrge regulation data using right side fid\n",
    "matches_df = matches_df.merge(regs_df, how=\"left\", left_on=\"RIGHT_FID\", right_on=\"LRID\", suffixes=(\"\", \"_y\"))\n",
    "\n",
    "# assign right side regulatiosn to home_, left side to nn_\n",
    "for reg in reg_list:\n",
    "    matches_df.loc[matches_df[\"boundary_side\"]==\"RIGHT\", f\"home_{reg}\"] = matches_df[f\"{reg}\"]\n",
    "    matches_df.loc[matches_df[\"boundary_side\"]==\"LEFT\", f\"nn_{reg}\"] = matches_df[f\"{reg}\"]\n",
    "\n",
    "# drop merged reg_df variables\n",
    "matches_df.drop(columns=reg_cols, inplace=True)\n",
    "\n",
    "print(\"Finished adding regulation variables!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5119f6-c244-4a4e-a5f1-ddb09662e43e",
   "metadata": {},
   "source": [
    "# Drop matches with missing (NaN) regulation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29b01f71-3a5d-44b8-a46f-04d327cf1ce1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-01T18:26:36.937717Z",
     "iopub.status.busy": "2022-11-01T18:26:36.937477Z",
     "iopub.status.idle": "2022-11-01T18:26:38.221096Z",
     "shell.execute_reply": "2022-11-01T18:26:38.220465Z",
     "shell.execute_reply.started": "2022-11-01T18:26:36.937698Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check count of nan values by match number for errors\n",
    "nan_counts = matches_df[matches_df[\"home_dupac_eff\"].isna() \n",
    "                        | matches_df[\"home_mxht_eff\"].isna()\n",
    "                        | matches_df[\"home_mulfam\"].isna()\n",
    "                        | matches_df[\"nn_dupac_eff\"].isna()\n",
    "                        | matches_df[\"nn_mxht_eff\"].isna()\n",
    "                        | matches_df[\"nn_mulfam\"].isna()\n",
    "                       ][\"match_num\"].value_counts()\n",
    "\n",
    "assert dict(nan_counts) == {1.0: 33320, 2.0: 28963, 3.0: 27002, 4.0: 23360, 5.0: 22872}\n",
    "\n",
    "# create dataframe without nan values\n",
    "matches_df2 = matches_df[matches_df[\"home_dupac_eff\"].notna() \n",
    "                         & matches_df[\"home_mxht_eff\"].notna()\n",
    "                         & matches_df[\"home_mulfam\"].notna()\n",
    "                         & matches_df[\"nn_dupac_eff\"].notna()\n",
    "                         & matches_df[\"nn_mxht_eff\"].notna()\n",
    "                         & matches_df[\"nn_mulfam\"].notna()\n",
    "                       ].copy()\n",
    "\n",
    "# error check\n",
    "assert len(matches_df2) == 2294046, \"incorrect observation count for matches_df2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99c243c-4224-4757-9e44-5fd06bbbfed3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-14T16:24:18.019970Z",
     "iopub.status.busy": "2022-10-14T16:24:18.019676Z",
     "iopub.status.idle": "2022-10-14T16:24:18.810023Z",
     "shell.execute_reply": "2022-10-14T16:24:18.809549Z",
     "shell.execute_reply.started": "2022-10-14T16:24:18.019935Z"
    },
    "tags": []
   },
   "source": [
    "# Keep the closest match (lowest match_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91981e2b-8cf4-4f6a-bf78-4c88a9281f17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-01T18:26:38.222296Z",
     "iopub.status.busy": "2022-11-01T18:26:38.222052Z",
     "iopub.status.idle": "2022-11-01T18:26:39.547477Z",
     "shell.execute_reply": "2022-11-01T18:26:39.546674Z",
     "shell.execute_reply.started": "2022-11-01T18:26:38.222278Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# keep the closest match (lowest match number)\n",
    "# sort by prop_id and distance \n",
    "matches_df2.sort_values(by=[\"PROP_ID\", \"match_num\"], ascending=True, inplace=True)\n",
    "\n",
    "# keep the first item\n",
    "matches_df2 = matches_df2.groupby(\"PROP_ID\").head(1).reset_index(drop=True)\n",
    "\n",
    "match_num_count = dict(matches_df2[\"match_num\"].value_counts())\n",
    "assert match_num_count == {1.0: 556233, 2.0: 15068, 3.0: 6973, 4.0: 4333, 5.0: 1798}, \"incorrect match_num count for matches_df2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f488491a-ed06-4043-aab2-cb3b1d2ef6f4",
   "metadata": {},
   "source": [
    "# Identify straight line boundary matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20982d0e-2364-45a4-988b-d634f5662562",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-01T18:26:39.549254Z",
     "iopub.status.busy": "2022-11-01T18:26:39.548889Z",
     "iopub.status.idle": "2022-11-01T18:32:54.348027Z",
     "shell.execute_reply": "2022-11-01T18:32:54.347462Z",
     "shell.execute_reply.started": "2022-11-01T18:26:39.549229Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished calculating straight line boundaries!\n"
     ]
    }
   ],
   "source": [
    "ORTH_LEN_M = 100 # set meter length for the orthogonal line\n",
    "n = 0\n",
    "\n",
    "for i, row in matches_df2.iterrows():\n",
    "\n",
    "    n+=1\n",
    "    \n",
    "    # get the address and boundary geographies\n",
    "    address_point = row[\"geometry_x\"] # the address, point object\n",
    "    boundary_line = row[\"geometry_fid\"] # the boundary, line onject\n",
    "\n",
    "    # return a line from address to the nearest point on boundary\n",
    "    nearest_x, nearest_y = nearest_points(address_point, boundary_line)\n",
    "    nearest_line = LineString([nearest_x, nearest_y])\n",
    "\n",
    "    # print(\"the nearest line:\", nearest_line)\n",
    "\n",
    "    # get left/right parallel line half the distance of cd_length\n",
    "    left = nearest_line.parallel_offset(ORTH_LEN_M / 2, \"left\")\n",
    "    right = nearest_line.parallel_offset(ORTH_LEN_M / 2, \"right\")\n",
    "\n",
    "    # store the left/right end points that are on/closest the boundary line\n",
    "    left_point = left.boundary[1]\n",
    "    right_point = right.boundary[0]\n",
    "\n",
    "#     # set epsg of the left/right points\n",
    "#     left_point = gpd.GeoSeries(left_point, crs = \"EPSG:26986\")\n",
    "#     right_point = gpd.GeoSeries(right_point, crs = \"EPSG:26986\")\n",
    "\n",
    "#     # set epsg for address point and boundary line\n",
    "#     address_point = gpd.GeoSeries(address_point, crs=\"EPSG:26986\")\n",
    "#     boundary_line = gpd.GeoSeries(boundary_line, crs=\"EPSG:26986\")\n",
    "\n",
    "    # calculate nearest distance from left/right orthogonal point to boundary line\n",
    "    left_dist_m = left_point.distance(boundary_line)\n",
    "    right_dist_m = right_point.distance(boundary_line)\n",
    "\n",
    "    matches_df2.loc[i, \"left_dist_m\"] = float(left_dist_m)\n",
    "    matches_df2.loc[i, \"right_dist_m\"] = float(right_dist_m)\n",
    "    matches_df2.loc[i, \"nearest_point\"] = str(nearest_y)\n",
    "    \n",
    "    print(f\"{n:,} of {len(matches_df2):,} orthogonals calculated\", end=\"\\r\")\n",
    "    \n",
    "matches_df2[\"straight_line\"] = 0\n",
    "\n",
    "matches_df2.loc[(matches_df2[\"left_dist_m\"]<=15) \n",
    "            & (matches_df2[\"right_dist_m\"]<=15),\n",
    "            \"straight_line\"] = 1\n",
    "\n",
    "final_df = matches_df2.copy()\n",
    "\n",
    "print(\"Finished calculating straight line boundaries!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd3717f-277f-4934-b542-76e015dbe598",
   "metadata": {},
   "source": [
    "# Error checks of final dataset before export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d47253ed-d029-465c-b4ec-83739b4819d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-01T18:32:54.349623Z",
     "iopub.status.busy": "2022-11-01T18:32:54.349281Z",
     "iopub.status.idle": "2022-11-01T18:32:54.513897Z",
     "shell.execute_reply": "2022-11-01T18:32:54.513424Z",
     "shell.execute_reply.started": "2022-11-01T18:32:54.349598Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished checking for errors in final data, none found!\n"
     ]
    }
   ],
   "source": [
    "# define list of columns to check for errors\n",
    "column_lst = [\"unique_id\",\n",
    "              \"zo_usety\",\n",
    "              \"reg_type\",\n",
    "              \"dist_m\",\n",
    "              \"match_num\",\n",
    "              \"home_mxht_eff\",\n",
    "              \"home_dupac_eff\",\n",
    "              \"home_mulfam\",\n",
    "              \"nn_mxht_eff\",\n",
    "              \"nn_dupac_eff\",\n",
    "              \"nn_mulfam\",\n",
    "              \"straight_line\"]\n",
    "\n",
    "# define error check values dictionary for output comparison\n",
    "error_check_dct = {'unique_id': \n",
    "                       {'count': 584405.0, \n",
    "                        'mean': 11821.47798, \n",
    "                        'std': 9412.81908, \n",
    "                        'min': 4.0, \n",
    "                        '25%': 3195.0, \n",
    "                        '50%': 8558.0, \n",
    "                        '75%': 22039.0, \n",
    "                        'max': 30070.0}, \n",
    "                   'zo_usety': \n",
    "                       {'count': 584405.0, \n",
    "                        'mean': 1.18516, \n",
    "                        'std': 0.57957, \n",
    "                        'min': 0.0, \n",
    "                        '25%': 1.0, \n",
    "                        '50%': 1.0, \n",
    "                        '75%': 1.0, \n",
    "                        'max': 4.0}, \n",
    "                   'reg_type': \n",
    "                       {'count': 584405.0, \n",
    "                        'mean': 164.53933, \n",
    "                        'std': 117.99648, \n",
    "                        'min': 1.0, \n",
    "                        '25%': 45.0, \n",
    "                        '50%': 191.0, \n",
    "                        '75%': 245.0, \n",
    "                        'max': 542.0}, \n",
    "                   'dist_m': \n",
    "                       {'count': 584405.0, \n",
    "                        'mean': 390.94435, \n",
    "                        'std': 578.23431, \n",
    "                        'min': 0.00161,\n",
    "                        '25%': 91.54269, \n",
    "                        '50%': 205.71943, \n",
    "                        '75%': 438.08227, \n",
    "                        'max': 7394.96124}, \n",
    "                   'match_num': \n",
    "                       {'count': 584405.0, \n",
    "                        'mean': 1.0842,\n",
    "                        'std': 0.42706, \n",
    "                        'min': 1.0, \n",
    "                        '25%': 1.0, \n",
    "                        '50%': 1.0, \n",
    "                        '75%': 1.0, \n",
    "                        'max': 5.0},\n",
    "                   'home_mxht_eff': \n",
    "                       {'count': 584405.0, \n",
    "                        'mean': 34.82389, \n",
    "                        'std': 10.33554, \n",
    "                        'min': 0.0, \n",
    "                        '25%': 35.0, \n",
    "                        '50%': 35.0, \n",
    "                        '75%': 35.0, \n",
    "                        'max': 356.0}, \n",
    "                   'home_dupac_eff': \n",
    "                       {'count': 584405.0, \n",
    "                        'mean': 13.05331, \n",
    "                        'std': 22.31415, \n",
    "                        'min': 0.0, \n",
    "                        '25%': 2.0, \n",
    "                        '50%': 5.0,\n",
    "                        '75%': 14.0, \n",
    "                        'max': 349.0}, \n",
    "                   'home_mulfam': \n",
    "                       {'count': 584405.0, \n",
    "                        'mean': 0.55077, \n",
    "                        'std': 0.49817, \n",
    "                        'min': 0.0, \n",
    "                        '25%': 0.0, \n",
    "                        '50%': 1.0, \n",
    "                        '75%': 1.0, \n",
    "                        'max': 1.0}, \n",
    "                   'nn_mxht_eff': \n",
    "                       {'count': 584405.0, \n",
    "                        'mean': 35.05074,\n",
    "                        'std': 15.78515, \n",
    "                        'min': 0.0, \n",
    "                        '25%': 35.0, \n",
    "                        '50%': 35.0, \n",
    "                        '75%': 38.0,\n",
    "                        'max': 400.0}, \n",
    "                   'nn_dupac_eff': \n",
    "                       {'count': 584405.0, \n",
    "                        'mean': 13.23601, \n",
    "                        'std': 24.24564, \n",
    "                        'min': 0.0, \n",
    "                        '25%': 1.0, \n",
    "                        '50%': 3.0, \n",
    "                        '75%': 14.0, \n",
    "                        'max': 349.0}, \n",
    "                   'nn_mulfam': \n",
    "                       {'count': 584405.0, \n",
    "                        'mean': 0.54173, \n",
    "                        'std': 0.49896, \n",
    "                        'min': 0.0, \n",
    "                        '25%': 0.0, \n",
    "                        '50%': 1.0, \n",
    "                        '75%': 1.0,\n",
    "                        'max': 1.0}, \n",
    "                   'straight_line': \n",
    "                       {'count': 584405.0, \n",
    "                        'mean': 0.14737, \n",
    "                        'std': 0.35447, \n",
    "                        'min': 0.0,\n",
    "                        '25%': 0.0, \n",
    "                        '50%': 0.0, \n",
    "                        '75%': 0.0, \n",
    "                        'max': 1.0}\n",
    "                  }\n",
    "\n",
    "# store output values for error check\n",
    "sum_stats_dct = {col: dict(round(final_df[col].describe(), 5)) \n",
    "                 for col in column_lst}\n",
    "\n",
    "# check observation count for errors\n",
    "assert len(final_df) == 584405, \"incorrect number of observations for final_gdf\"\n",
    "\n",
    "# check boundary side matches for error\n",
    "side_counts = dict(final_df[\"boundary_side\"].value_counts())\n",
    "assert side_counts[\"LEFT\"] == 292934, \"incorrect count of left side matches\"\n",
    "assert side_counts[\"RIGHT\"] == 291471, \"incorrect count of right side matches\"\n",
    "\n",
    "# check remaining variables for error\n",
    "for x in error_check_dct:\n",
    "    assert sum_stats_dct[x] == error_check_dct[x], f\"summary stats for {x} do not match stored values\"\n",
    "\n",
    "print(\"Finished checking for errors in final data, none found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deca47e8-6149-4104-a6ea-b3a79501c271",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Export data and save log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d25a74fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-01T18:35:34.147302Z",
     "iopub.status.busy": "2022-11-01T18:35:34.147014Z",
     "iopub.status.idle": "2022-11-01T18:36:31.628448Z",
     "shell.execute_reply": "2022-11-01T18:36:31.627919Z",
     "shell.execute_reply.started": "2022-11-01T18:35:34.147278Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, 584,405 observations written!\n"
     ]
    }
   ],
   "source": [
    "# set save and log paths\n",
    "log_path = \"/home/a1nfc04/Documents/boston_zoning_sdrive/python_programs/closest_boundary_matches/closest_boundary_matches_noroads_log.txt\"\n",
    "\n",
    "# save data paths\n",
    "save_file = \"closest_boundary_matches_noroads.csv\"\n",
    "save_folder = \"/home/a1nfc04/Documents/boston_zoning_sdrive/data/closest_boundary_matches\"\n",
    "save_path = os.path.join(save_folder, save_file)\n",
    "\n",
    "# subdir for old exports\n",
    "old_saves_folder = \"/home/a1nfc04/Documents/boston_zoning_sdrive/data/closest_boundary_matches/old_export_versions\"\n",
    "\n",
    "# check if current save version exists, if so then move it to the old versions folder\n",
    "contents = [item for item in os.listdir(save_folder)]\n",
    "if save_file in contents:\n",
    "\n",
    "    # create previous saves folder is doesn't exist\n",
    "    if os.path.isdir(old_saves_folder) == False:\n",
    "        os.makedirs(old_saves_folder)\n",
    "    \n",
    "    # move file to sub-directory\n",
    "    old_file_path = os.path.join(old_saves_folder, save_file)\n",
    "    shutil.move(save_path, old_file_path)\n",
    "    \n",
    "    # rename the old file with creation date\n",
    "    create_date = datetime.fromtimestamp(os.path.getmtime(old_file_path)).strftime(\"_%Y-%m-%d\")\n",
    "    new_file_name = os.path.splitext(old_file_path)[0] + create_date + \".csv\"   \n",
    "    os.rename(old_file_path, new_file_name)\n",
    "    \n",
    "# create log and save date stamps\n",
    "end_time = datetime.now()\n",
    "\n",
    "duration = end_time - start_time\n",
    "\n",
    "duration_in_s = (duration.days * 24 * 60 * 60) + duration.seconds\n",
    "mins, secs = divmod(duration_in_s, 60)\n",
    "hours, mins = divmod(mins, 60)\n",
    "days, hours  = divmod(hours, 24)\n",
    "\n",
    "# save dataset as .csv\n",
    "final_df.to_csv(save_path, index = False)\n",
    "\n",
    "# write to log\n",
    "with open(log_path,'a') as file:\n",
    "    file.write(f\"Last run on {datetime.now().strftime('%D at %I:%M:%S %p')}\\n\")\n",
    "    file.write(f\"{len(final_df):,} observations written to {save_path} \\n\")\n",
    "    file.write(f\"Total run time: {days} days, {hours:02} hours, {mins:02} minutes, {secs:02} seconds \\n\\n\")\n",
    "\n",
    "# Done!\n",
    "print(f\"Done, {len(final_df):,} observations written!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e163b77-89a5-4839-a032-adb153fed0e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boston_zoning",
   "language": "python",
   "name": "boston_zoning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
